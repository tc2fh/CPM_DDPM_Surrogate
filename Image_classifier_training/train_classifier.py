'''
Script using pytorch lightning to train an Efficientnet_v2 model on single-channel images generated by the CC3D mechanistic model. 
We modify the EfficientNet_v2 model to accept single-channel input images and classify them into 25 classes based on the contact and decay parameters used in the CC3D simulations.
'''

import torch
import torchvision.models as models
import torch.nn.functional as F
from torch import nn
from torchvision.ops.misc import Conv2dNormActivation
from torch.utils.data import Dataset, DataLoader
import zarr
import numpy as np
import os
import re
from torchvision import transforms
import lightning.pytorch as pl
from torch.utils.data import DataLoader
from lightning.pytorch.plugins.environments import SLURMEnvironment
import signal
from tqdm import tqdm

torch.set_float32_matmul_precision('medium')

NUM_GPUS = torch.cuda.device_count()
NUM_WORKERS = int(os.getenv("SLURM_CPUS_PER_TASK", "1"))  # Default to 1 if not set
NUM_NODES = int(os.getenv("SLURM_NNODES", "1"))  # Default to 1 if not set
LEARN_RATE = float(os.getenv("LEARN_RATE", "0.001"))  # Default to 0.0001 if not set
MAX_EPOCHS = int(os.getenv("MAX_EPOCHS", "100"))  # Default to 100 if not set
SUMMARY_PATH = os.getenv("SUMMARY_PATH",os.path.join(os.path.dirname(__file__), 'model_train_logs', 'classifier'))
BATCH_SIZE = int(os.getenv("DATA_BATCH_SIZE", "200"))  # Default to 16 if not set

DATA_PATH = os.getenv("ZIPSTORE_DATA_DIRECTORY", os.path.join(os.path.dirname(__file__), 'Generative_Data', 'classifier_train_test'))
TRAIN_DIR = os.path.join(DATA_PATH, 'train')
VAL_DIR = os.path.join(DATA_PATH, 'test')
TEST_DIR = os.path.join(DATA_PATH, 'eval') #eval set generated separately then moved into this folder on HPC cluster

# EfficientNet_v2_s_1c model with 25 classes and single channel input
class EfficientNet_v2_s_1c(nn.Module):
    def __init__(self, num_classes=25):
        super().__init__()
        
        # Load the EfficientNet V2-S model without pretrained weights and with the specified number of classes
        self.model = models.efficientnet_v2_s(weights=None, num_classes=num_classes)
        
        # Modify the first Conv2dNormActivation layer to accept 1 channel instead of 3
        self.model.features[0][0] = Conv2dNormActivation(
            in_channels=1,  # Change the input channels to 1
            out_channels=self.model.features[0][0].out_channels,  
            kernel_size=self.model.features[0][0].kernel_size,  
            stride=self.model.features[0][0].stride,  
            padding=self.model.features[0][0].padding,  
            norm_layer=nn.BatchNorm2d, 
            activation_layer=nn.SiLU  
        )
    
    def forward(self, x):
        return self.model(x)
    
# EfficientNet_v2_m_1c model with 25 classes and single channel input
class EfficientNet_v2_m_1c(nn.Module):
    def __init__(self, num_classes=25):
        super().__init__()
        
        # Load the EfficientNet V2-M model without pretrained weights and with the specified number of classes
        self.model = models.efficientnet_v2_m(weights=None, num_classes=num_classes)
        
        # Modify the first Conv2dNormActivation layer to accept 1 channel instead of 3
        self.model.features[0][0] = Conv2dNormActivation(
            in_channels=1,  # Change the input channels to 1
            out_channels=self.model.features[0][0].out_channels,  
            kernel_size=self.model.features[0][0].kernel_size,  
            stride=self.model.features[0][0].stride,  
            padding=self.model.features[0][0].padding,  
            norm_layer=nn.BatchNorm2d, 
            activation_layer=nn.SiLU  
        )
    
    def forward(self, x):
        return self.model(x)
    
# EfficientNet_v2_m_1c model with 25 classes and single channel input
class EfficientNet_v2_l_1c(nn.Module):
    def __init__(self, num_classes=25):
        super().__init__()
        
        # Load the EfficientNet V2-M model without pretrained weights and with the specified number of classes
        self.model = models.efficientnet_v2_l(weights=None, num_classes=num_classes)
        
        # Modify the first Conv2dNormActivation layer to accept 1 channel instead of 3
        self.model.features[0][0] = Conv2dNormActivation(
            in_channels=1,  # Change the input channels to 1
            out_channels=self.model.features[0][0].out_channels,  
            kernel_size=self.model.features[0][0].kernel_size,  
            stride=self.model.features[0][0].stride,  
            padding=self.model.features[0][0].padding,  
            norm_layer=nn.BatchNorm2d, 
            activation_layer=nn.SiLU  
        )
    
    def forward(self, x):
        return self.model(x)

class ClassificationEfficientNet(pl.LightningModule):
    def __init__(self, num_classes=25, learning_rate=1e-3):
        super().__init__()
        self.model = EfficientNet_v2_s_1c(num_classes=num_classes) #change to EfficientNet_v2_s_1c, EfficientNet_v2_m_1c, or EfficientNet_v2_l_1c for small, mid, large model. Small model was used for the paper.
        self.learning_rate = learning_rate
        self.num_classes = num_classes
        self.criterion = F.cross_entropy
    
    def forward(self, x):
        return self.model(x)
    
    def training_step(self, batch, batch_idx):
        images, labels = batch
        outputs = self(images)
        loss = self.criterion(outputs, labels)
        self.log('train_loss', loss, sync_dist=True)
        return loss
    
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        outputs = self(images)
        loss = self.criterion(outputs, labels)
        acc = (outputs.argmax(dim=1) == labels).float().mean()
        self.log('val_loss', loss, sync_dist=True)
        self.log('val_acc', acc, sync_dist=True)
        return loss
    
    def test_step(self, batch, batch_idx):
        images, labels = batch
        outputs = self(images)
        loss = self.criterion(outputs, labels)
        acc = (outputs.argmax(dim=1) == labels).float().mean()
        self.log('test_loss', loss, sync_dist=True)
        self.log('test_acc', acc, sync_dist=True)
        return loss
    
    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=LEARN_RATE)

class ZarrDataset(Dataset):
    def __init__(self, root_dir, transform=None, dataset_type='train'):
        """
        Args:
            root_dir (string): Directory with all the .zarr.zip files.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """

        print(f'Loading dataset {dataset_type}...')
        self.root_dir = root_dir
        self.transform = transform
        self.dataset_type = dataset_type

        # List all zarr.zip files in the directory
        self.files = [f for f in os.listdir(root_dir) if f.endswith('.zarr.zip')]

        # Create a set to store all unique label tuples
        self.label_set = set()
        self.image_info = []
        

        # Collect all unique label tuples
        for file in tqdm(self.files):
            with zarr.open(os.path.join(self.root_dir, file), mode='r') as zarr_file:
                #note that train images are under zarr group 'train' and test images are under zarr group 'test'
                num_images = zarr_file[self.dataset_type].shape[0] # Get the number of images in the file
                label_tuple = self.get_label(file)
                self.label_set.add(label_tuple)
                for i in range(num_images):
                    self.image_info.append((file, i, label_tuple))  # (filename, image_index, label_tuple)

        # Create a mapping from label tuples to integers
        self.label_mapping = {label: idx for idx, label in enumerate(sorted(self.label_set))}
        print('Label mapping:', self.label_mapping) # Print the label mapping

    def get_label(self, filename):
        """Extract the contact_param and decay_param and create a label tuple."""
        try:
            # Split the filename and extract parameters
            parts = filename.replace('.zarr.zip', '').split('_')
            contact_param = int(parts[1])
            decay_param = float(parts[3])
            return (contact_param, decay_param)
        except (IndexError, ValueError) as e:
            raise ValueError(f"Filename {filename} does not match expected pattern.") from e

    def __len__(self):
        return len(self.image_info)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        # Get the file name, image index, and label tuple for the requested index
        file_name, image_index, label_tuple = self.image_info[idx]
        with zarr.open(os.path.join(self.root_dir, file_name), mode='r') as zarr_file:
            # Convert the label tuple to an integer
            label = self.label_mapping[label_tuple]

            # Load the specific image and convert to float32 from boolean
            image = zarr_file[self.dataset_type][image_index].astype(np.float32)

        # Apply transformation if provided
        if self.transform:
            image = self.transform(image)
        
        # Convert back to tensor if not already done by transforms
        if not isinstance(image, torch.Tensor):
            image = transforms.ToTensor()(image)

        return image, torch.tensor(label, dtype=torch.long)

class ZarrDataModule(pl.LightningDataModule):
    def __init__(self, train_dir, val_dir, test_dir, batch_size=16, num_workers=4):
        super().__init__()
        self.train_dir = train_dir
        self.val_dir = val_dir
        self.test_dir = test_dir
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.transform = None

    def setup(self, stage=None):
        self.train_dataset = ZarrDataset(root_dir=self.train_dir, transform=self.transform, dataset_type='train')
        self.val_dataset = ZarrDataset(root_dir=self.val_dir, transform=self.transform, dataset_type='test')
        self.test_dataset = ZarrDataset(root_dir=self.test_dir, transform=self.transform, dataset_type='eval')

    def train_dataloader(self):
        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, persistent_workers=True, prefetch_factor=10, pin_memory=True)

    def val_dataloader(self):
        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=True, prefetch_factor=10, pin_memory=True)

    def test_dataloader(self):
        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=True, prefetch_factor=10, pin_memory=True)

class NpyDataModule(pl.LightningDataModule):
    def __init__(self, train_dir, val_dir, test_dir, batch_size=16, num_workers=4, transform=None):
        super().__init__()
        self.train_dir = train_dir
        self.val_dir = val_dir
        self.test_dir = test_dir
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.transform = transform

    def setup(self, stage=None):
        self.train_dataset = NpyDataset(root_dir=self.train_dir, transform=self.transform)
        self.val_dataset = NpyDataset(root_dir=self.val_dir, transform=self.transform)
        self.test_dataset = NpyDataset(root_dir=self.test_dir, transform=self.transform)

    def train_dataloader(self):
        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, persistent_workers=True, prefetch_factor=10, pin_memory=True)

    def val_dataloader(self):
        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=True, prefetch_factor=10, pin_memory=True)

    def test_dataloader(self):
        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=True, prefetch_factor=10, pin_memory=True)

class NpyDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        """
        Args:
            root_dir (string): Directory with all the class subfolders.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        print(f'Loading dataset from {root_dir}...')
        self.root_dir = root_dir
        self.transform = transform

        # List all subfolders in the directory
        self.class_folders = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]

        # Create a set to store all unique label tuples
        self.label_set = set()
        self.image_info = []

        # Collect all unique label tuples and image paths
        for folder in tqdm(self.class_folders):
            label_tuple = self.get_label(os.path.basename(folder))
            self.label_set.add(label_tuple)
            for file in os.listdir(folder):
                if file.endswith('.npy'):
                    self.image_info.append((os.path.join(folder, file), label_tuple))  # (file_path, label_tuple)

        # Create a mapping from label tuples to integers
        self.label_mapping = {label: idx for idx, label in enumerate(sorted(self.label_set))}
        print('Label mapping:', self.label_mapping)  # Print the label mapping

    def get_label(self, folder_name):
        """Extract the contact_param and decay_param from the folder name."""
        try:
            # Split the folder name and extract parameters
            parts = folder_name.split('_')
            contact_param = int(parts[1])
            decay_param = float(parts[3])
            return (contact_param, decay_param)
        except (IndexError, ValueError) as e:
            raise ValueError(f"Folder name {folder_name} does not match expected pattern.") from e

    def __len__(self):
        return len(self.image_info)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        # Get the file path and label tuple for the requested index
        file_path, label_tuple = self.image_info[idx]
        label = self.label_mapping[label_tuple]

        # Load the image
        image = np.load(file_path).astype(np.float32)

        # Apply transformation if provided
        if self.transform:
            image = self.transform(image)

        # Convert back to tensor if not already done by transforms
        if not isinstance(image, torch.Tensor):
            image = transforms.ToTensor()(image)

        return image, torch.tensor(label, dtype=torch.long)


def main():
    pl.seed_everything(1, workers=True)

    print('num gpus:', NUM_GPUS)
    print('num workers:', NUM_WORKERS)
    print('num nodes:', NUM_NODES)
    print('learn rate:', LEARN_RATE)
    print('max epochs:', MAX_EPOCHS)
    print('batch size:', BATCH_SIZE)

    data_module = ZarrDataModule(train_dir=TRAIN_DIR, val_dir=VAL_DIR, test_dir=TEST_DIR, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
    
    model = ClassificationEfficientNet(learning_rate=LEARN_RATE)

    logger = pl.loggers.TensorBoardLogger(SUMMARY_PATH, name='classifier')

    checkpoint_callback = pl.callbacks.ModelCheckpoint(
        monitor='val_acc',    # Metric to monitor
        filename='model-{epoch:02d}-{val_acc:.2f}',
        save_top_k=3,          # Number of best models to save
        mode='max',            # Save models with highest val_acc
    )

    trainer = pl.Trainer(
        accelerator='gpu', 
        devices=NUM_GPUS,  
        strategy='ddp',    
        num_nodes=NUM_NODES,  
        max_epochs=MAX_EPOCHS,        
        precision='16-mixed',          # Use FP16 for training
        callbacks=[checkpoint_callback],
        logger=logger,
        profiler="simple", #for profiling
        plugins=[SLURMEnvironment(requeue_signal=signal.SIGUSR1)], #for slurm requeueing and signal handling
    )

    trainer.fit(model, data_module)

    trainer.test(model, datamodule=data_module)


if __name__ == "__main__":
    main()

